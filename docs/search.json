[{"path":"https://hendersontrent.github.io/theft/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 Trent Henderson Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://hendersontrent.github.io/theft/articles/theft.html","id":"purpose","dir":"Articles","previous_headings":"","what":"Purpose","title":"Introduction to theft","text":"theft facilitates user-friendly access structured analytical workflow extraction, analysis, visualisation time-series features. structured workflow presented graphic (note theft many functions displayed graphic — keep reading ):","code":""},{"path":"https://hendersontrent.github.io/theft/articles/theft.html","id":"core-calculation-functions","dir":"Articles","previous_headings":"","what":"Core calculation functions","title":"Introduction to theft","text":"explore package functionality, going use dataset comes standard theft called simData. dataset contains collection randomly generated time series six different types processes. dataset can accessed via: data follows following structure:","code":"theft::simData head(simData) #>        values timepoint               id        process #> 1: -0.6264538         1 Gaussian Noise_1 Gaussian Noise #> 2:  0.1836433         2 Gaussian Noise_1 Gaussian Noise #> 3: -0.8356286         3 Gaussian Noise_1 Gaussian Noise #> 4:  1.5952808         4 Gaussian Noise_1 Gaussian Noise #> 5:  0.3295078         5 Gaussian Noise_1 Gaussian Noise #> 6: -0.8204684         6 Gaussian Noise_1 Gaussian Noise"},{"path":"https://hendersontrent.github.io/theft/articles/theft.html","id":"calculating-feature-summary-statistics","dir":"Articles","previous_headings":"Core calculation functions","what":"Calculating feature summary statistics","title":"Introduction to theft","text":"core function automates calculation feature statistics calculate_features. can choose subset features calculate feature_set argument. choices currently \"catch22\", \"feasts\", \"Kats\", \"tsfeatures\", \"tsfresh\", /\"TSFEL\". Note Kats, tsfresh TSFEL Python packages. R package reticulate used call Python code uses packages applies within broader tidy data philosophy embodied theft. present, depending input time-series, theft provides access \\(>1200\\) features. Prior using theft (want use Kats, tsfresh TSFEL feature sets - R-based sets run fine) working Python installation download Kats using instructions located , tsfresh TSFEL . example catch22 set: Note catch22 set can set additional catch24 argument calculate mean standard deviation addition standard 22 features: Note want use Python-based packages, must first tell R (prior running calculate_features) Python location computer contains installed libraries. can done via init_theft function, path_to_python string specifying filepath location. example, (Trent), filepath correct Python \"~/opt/anaconda3/bin/python\" enter path_to_python argument. need call init_theft per R session. tidy dataframe included features set correspond available dataframe feature_list: NOTE: using tsfresh feature set, might want consider tsfresh_cleanup argument calculate_features. argument defaults FALSE specifies whether use -built tsfresh relevant feature filter . detailed comparison six feature sets, see paper detailed review1.","code":"feature_matrix <- calculate_features(data = simData,                                       id_var = \"id\",                                       time_var = \"timepoint\",                                       values_var = \"values\",                                       group_var = \"process\",                                       feature_set = \"catch22\",                                      seed = 123) feature_matrix <- calculate_features(data = simData,                                       id_var = \"id\",                                       time_var = \"timepoint\",                                       values_var = \"values\",                                       group_var = \"process\",                                       feature_set = \"catch22\",                                      catch24 = TRUE,                                      seed = 123) init_theft(path_to_python) head(feature_list) #>   feature_set                  feature #> 1     catch22       DN_HistogramMode_5 #> 2     catch22      DN_HistogramMode_10 #> 3     catch22                CO_f1ecac #> 4     catch22           CO_FirstMin_ac #> 5     catch22 CO_HistogramAMI_even_2_5 #> 6     catch22            CO_trev_1_num"},{"path":"https://hendersontrent.github.io/theft/articles/theft.html","id":"data-quality-checks","dir":"Articles","previous_headings":"","what":"Data quality checks","title":"Introduction to theft","text":"package comes function visualise data types calculated feature vectors. useful inspecting features might need dropped due large proportions undesirable (e.g., NA, NaN etc.) values.","code":"plot_quality_matrix(feature_matrix)"},{"path":"https://hendersontrent.github.io/theft/articles/theft.html","id":"normalisingscaling-functions","dir":"Articles","previous_headings":"","what":"Normalising/scaling functions","title":"Introduction to theft","text":"Putting calculated feature vectors equal scale crucial statistical machine learning model variables high variance can adversely impact model’s capacity fit data appropriately, learn appropriate weight values, minimise loss function. theft includes functions normalise_feature_vector rescale vector values (e.g. vector values participants study SB_BinaryStats_mean_longstretch1 feature), normalise_feature_frame rescale vector within dataframe variety different ranges ease--use. Current transformations available package include (note apply linear rescaling unit interval end): z-score - \"z-score\" Sigmoid - \"Sigmoid\" Outlier-robust Sigmoid (credit Ben Fulcher creating original MATLAB version) - \"RobustSigmoid\" Min-max - \"MinMax\" Dataframe-based normalisation can performed using following:","code":"normed <- normalise_feature_frame(feature_matrix,                                    names_var = \"names\",                                    values_var = \"values\",                                    method = \"RobustSigmoid\")"},{"path":"https://hendersontrent.github.io/theft/articles/theft.html","id":"data-visualisation-and-low-dimensional-project-functions","dir":"Articles","previous_headings":"","what":"Data visualisation and low-dimensional project functions","title":"Introduction to theft","text":"package also comes built-plotting engine calculating visualising many types statistical graphics: Feature time-series matrix heatmap Low dimensional projections feature space scatterplot (along numerical results) Pairwise correlation matrix heatmap","code":""},{"path":"https://hendersontrent.github.io/theft/articles/theft.html","id":"feature-matrices","dir":"Articles","previous_headings":"Data visualisation and low-dimensional project functions","what":"Feature matrices","title":"Introduction to theft","text":"function plot_all_features (deprecated version: plot_feature_matrix) takes calculated features produces ggplot object heatmap showing feature vectors across x axis time series y axis. Prior plotting, function hierarchically clusters data across rows columns visually highlight empirical structure. Note several options hierarchical clustering linkage algorithm use: \"average\" (default) \"ward.D\" \"ward.D2\" \"single\" \"complete\" \"mcquitty\" \"median\" \"centroid\" See hclust documentation information. Note legend plot (matrix visualisations theft) discretised visual clarity continuous legends can difficult interpret meaningful value differences easily.  set interactive = TRUE function return interactive plot using plotly lets hover entries matrix better understand . especially useful dataset large.","code":"plot_all_features(feature_matrix,                    is_normalised = FALSE,                    id_var = \"id\",                    method = \"RobustSigmoid\",                   clust_method = \"average\",                   interactive = FALSE) plot_feature_matrix(feature_matrix,                      is_normalised = FALSE,                      id_var = \"id\",                      method = \"RobustSigmoid\",                     clust_method = \"average\",                     interactive = TRUE)"},{"path":"https://hendersontrent.github.io/theft/articles/theft.html","id":"low-dimensional-projections","dir":"Articles","previous_headings":"Data visualisation and low-dimensional project functions","what":"Low dimensional projections","title":"Introduction to theft","text":"function plot_low_dimension takes calculated features, calculates principal components analysis (PCA) t-distributed stochastic neighbour embedding (t-SNE), produces ggplot object scatterplot showing first second principal components x y axis respectively, individual explained variance (PCA selected), time series point. plot = FALSE function returns dataframe results. variable specified group_var argument, scatterplot points automatically coloured group.  Alternatively, t-SNE version can specified similar fashion, perplexity hyperparameter able controlled user. Typical values range 5 50, depending size data. lower levels perplexity, local variations tend dominate, high levels perplexity, results can uninterpretable clusters can merge. See interactive article detailed review.","code":"plot_low_dimension(feature_matrix,                     is_normalised = FALSE,                     id_var = \"id\",                     group_var = \"group\",                     method = \"RobustSigmoid\",                     low_dim_method = \"PCA\",                     plot = TRUE,                    show_covariance = TRUE,                    seed = 123) plot_low_dimension(feature_matrix,                     is_normalised = FALSE,                     id_var = \"id\",                     group_var = \"group\",                     method = \"RobustSigmoid\",                     low_dim_method = \"t-SNE\",                     perplexity = 10,                     plot = TRUE,                    show_covariance = FALSE,                    seed = 123)"},{"path":[]},{"path":"https://hendersontrent.github.io/theft/articles/theft.html","id":"time-series-correlations","dir":"Articles","previous_headings":"Data visualisation and low-dimensional project functions > Pairwise correlations","what":"Time-series correlations","title":"Introduction to theft","text":"function plot_ts_correlations automates calculation correlations values unique time series, hierarchical clustering rows columns correlations, production final heatmap graphic. can switch default Pearson correlation Spearman rank correlation changing cor_method argument spearman. visualisation might always highly informative, can useful take quick glance regardless.  , set interactive = TRUE function return interactive plot using plotly lets hover entries matrix better understand .","code":"plot_ts_correlations(simData,                       is_normalised = FALSE,                       id_var = \"id\",                       time_var = \"timepoint\",                      values_var = \"values\",                      method = \"RobustSigmoid\",                      cor_method = \"pearson\",                      clust_method = \"average\",                      interactive = FALSE) plot_ts_correlations(simData,                       is_normalised = FALSE,                       id_var = \"id\",                       time_var = \"timepoint\",                      values_var = \"values\",                      method = \"RobustSigmoid\",                      cor_method = \"spearman\",                      clust_method = \"average\",                      interactive = TRUE)"},{"path":"https://hendersontrent.github.io/theft/articles/theft.html","id":"feature-vector-correlations","dir":"Articles","previous_headings":"Data visualisation and low-dimensional project functions > Pairwise correlations","what":"Feature vector correlations","title":"Introduction to theft","text":"Similarly, one can also plot correlations feature vectors using plot_feature_correlations. general argument structure plot_ts_correlations.","code":"plot_feature_correlations(feature_matrix,                            is_normalised = FALSE,                            id_var = \"id\",                            names_var = \"names\",                           values_var = \"values\",                           method = \"RobustSigmoid\",                           cor_method = \"pearson\",                           clust_method = \"average\",                           interactive = FALSE)"},{"path":[]},{"path":"https://hendersontrent.github.io/theft/articles/theft.html","id":"feature-by-feature","dir":"Articles","previous_headings":"Time-series classification","what":"Feature-by-feature","title":"Introduction to theft","text":"Since feature-based time-series analysis shown particular promise classification problems, theft includes functionality exploring group separation addition low dimensional representation. compute_top_features function takes computed features performs following: Processes data ready analysis Computes classification algorithm statistical model entire input dataframe Extracts individual feature performance classification algorithm using designated performance metric Filters feature data top n performing features (n specified user) Plots feature \\(\\times\\) feature correlation matrix heatmap top performing features Plots group violin plots coloured class label top performing features analysis useful can help guide researchers toward efficient appropriate interpretation high-performing features (exist) helps protect -interpretation feature values. function returns object three components summarise steps: ResultsTable – dataframe containing feature names, feature set membership, performance statistics top performing features FeatureFeatureCorrelationPlot – ggplot containing pairwise correlations top performing features represented heatmap ViolinPlots – ggplot containing matrix violin plots showing class discrimination feature code produces analysis multiclass problem using Gaussian process classifier radial basis function kernel. implements custom “empirical null” procedure estimating p-value based classification accuracy real data compared distribution null samples built classification accuracies data random class label shuffles. also known permutation testing (see document2 good overview). Note higher numbers permutation samples means better empirical null distribution can generated. recommended run 100-1000 permutations, though comes considerable computation time. ’ll enable k-fold cross-validation procedure good measure. Note using procedures increases computation time. Electing use empirical null faster, top features determined based classification accuracy features p-values. , use_k_fold = FALSE, model instead fit data predict classes based data (caret language, equivalent caret::trainControl(method = \"none\") calling predict input data getting accuracy confusion matrix two). likely lead overfitting, return results orders magnitude faster use_k_fold = TRUE. Importantly, argument null_testing_method two choices: ModelFreeShuffles – Generates num_permutations number random shuffles group labels computes proportion match, returning distribution “accuracies”. model extremely fast involves null model fitting NullModelFits – Generates num_permutations number models trained tested data class label shuffled. method slow fits separate null models num_permutations shuffle use ModelFreeShuffles throughout tutorial reduce computation time. p_value_method also two choices: empirical – calculates proportion null classification accuracies equal greater main model accuracy gaussian – calculates mean standard deviation null distribution analytically calculate p-value main model . Initial package testing indicated null distributions (especially increasing num_permutations) approximately Gaussian, meaning approach can feasibly used Note ModelFreeShuffles incompatible pool_empirical_null = TRUE null distributions exactly . , set pool_empirical_null = TRUE compute statistical analysis feature entire pooled empirical null classification results features. Setting FALSE compute p-value feature empirical null distribution. IMPORTANT NOTE: theft currently label results “statistically significant”. intend work, please adjust multiple comparisons considering numerous results threshold (e.g., \\(\\alpha = 0.05\\)) ensure decisions make grounded careful thought. seed argument allows specify number fix R’s random number generator reproducible results. defaults 123 nothing provided. component named can accessed regular use $ operator list indexing (return object). ’s top rows: equivalently achieve : feature-feature correlation plots accessed second object:  violin plots accessed third object:  two-class problems, users can fit statistical models directly compute p-values specifying one following models string argument test_method: \"t-test\", \"wilcox\" \"binomial logistic\". theft special procedures three options two-class problem registered thus none function arguments pertaining empirical null testing classification model parameters used. multiclass problems (binary), users can specify model name string valid method name popular caret package theft pass relevant sub-procedures make use arguments relating k-fold cross-validation, permutation testing, p-value calculation.","code":"outputs <- compute_top_features(feature_matrix,                                  id_var = \"id\",                                  group_var = \"group\",                                 num_features = 10,                                  normalise_violin_plots = FALSE,                                 method = \"RobustSigmoid\",                                 cor_method = \"pearson\",                                 test_method = \"gaussprRadial\",                                 clust_method = \"average\",                                 use_balanced_accuracy = FALSE,                                 use_k_fold = TRUE,                                 num_folds = 10,                                 use_empirical_null =  TRUE,                                 null_testing_method = \"ModelFreeShuffles\",                                 p_value_method = \"gaussian\",                                 num_permutations = 10,                                 pool_empirical_null = FALSE,                                 seed = 123) head(outputs$ResultsTable) #>                                        feature  accuracy p_value_accuracy #> 1     catch22_sp_summaries_welch_rect_area_5_1 0.9500000    3.583919e-134 #> 2     catch22_sp_summaries_welch_rect_centroid 0.8722222    1.977506e-109 #> 3         catch22_fc_local_simple_mean3_stderr 0.8222222     7.091601e-95 #> 4                            catch22_co_f1ecac 0.7888889     9.262259e-86 #> 5           catch22_sb_motif_three_quantile_hh 0.7777778     7.962008e-83 #> 6 catch22_co_embed2_dist_tau_d_expfit_meandiff 0.6944444     1.761311e-62 #>   classifier_name               statistic_name #> 1   gaussprRadial Mean classification accuracy #> 2   gaussprRadial Mean classification accuracy #> 3   gaussprRadial Mean classification accuracy #> 4   gaussprRadial Mean classification accuracy #> 5   gaussprRadial Mean classification accuracy #> 6   gaussprRadial Mean classification accuracy head(outputs[[1]]) print(outputs$FeatureFeatureCorrelationPlot) print(outputs$ViolinPlots)"},{"path":"https://hendersontrent.github.io/theft/articles/theft.html","id":"multi-feature","dir":"Articles","previous_headings":"Time-series classification","what":"Multi-feature","title":"Introduction to theft","text":"multi-feature option also available. fit_multivariable_classifier function fits features instead individual features estimate classification accuracy. can split feature set (by_set argument set TRUE) enable systematic comparisons made available theft. save computation time tutorial, analyse catch22 (by_set = TRUE demonstrate automated plotting functionality), comparing multiple calculated feature sets recommended practice. Now can use multi-feature functionality (note similarity options single feature version specified ): can now access various named objects returned function, include: FeatureSetResultsPlot (by_set set TRUE) – ggplot displaying classification accuracy (balanced classification accuracy use_balanced_accuracy set TRUE) feature set TestStatistics – dataframe containing summary test statistics (p-values use_empirical_null set TRUE) RawClassificationResults – dataframe containing classification accuracies results main null prediction ’s feature set comparison plot (note balanced classes, case, accuracy \\(=\\) balanced accuracy.):  ’s test statistics summary: ’s raw classifier results: Note multi-feature version, valid caret method names able used specify test_method.","code":"multi_outputs <- fit_multi_feature_classifier(feature_matrix,                                                id_var = \"id\",                                                group_var = \"group\",                                                by_set = TRUE,                                                test_method = \"svmLinear\",                                               use_balanced_accuracy = TRUE,                                               use_k_fold = TRUE,                                               num_folds = 10,                                               use_empirical_null =  TRUE,                                               null_testing_method = \"ModelFreeShuffles\",                                               p_value_method = \"gaussian\",                                               num_permutations = 10,                                               seed = 123) print(multi_outputs$FeatureSetResultsPlot) head(multi_outputs$TestStatistics) #>    method  accuracy p_value_accuracy balanced_accuracy #> 1 catch22 0.6555556     5.452103e-54         0.6555556 #>   p_value_balanced_accuracy classifier_name #> 1              5.452103e-54       svmLinear #>                                                      statistic_name #> 1 Mean classification accuracy and balanced classification accuracy head(multi_outputs$RawClassificationResults) #>    accuracy accuracy_sd balanced_accuracy balanced_accuracy_sd category #> 1 0.6555556  0.04382281         0.6555556           0.04382281     Main #> 2 0.1222222          NA         0.1222222                   NA     Null #> 3 0.2277778          NA         0.2277778                   NA     Null #> 4 0.1444444          NA         0.1444444                   NA     Null #> 5 0.1444444          NA         0.1444444                   NA     Null #> 6 0.1444444          NA         0.1444444                   NA     Null #>              method num_features_used classifier_name #> 1           catch22                22       svmLinear #> 2 ModelFreeShuffles                NA       svmLinear #> 3 ModelFreeShuffles                NA       svmLinear #> 4 ModelFreeShuffles                NA       svmLinear #> 5 ModelFreeShuffles                NA       svmLinear #> 6 ModelFreeShuffles                NA       svmLinear #>                                                      statistic_name #> 1 Mean classification accuracy and balanced classification accuracy #> 2 Mean classification accuracy and balanced classification accuracy #> 3 Mean classification accuracy and balanced classification accuracy #> 4 Mean classification accuracy and balanced classification accuracy #> 5 Mean classification accuracy and balanced classification accuracy #> 6 Mean classification accuracy and balanced classification accuracy"},{"path":"https://hendersontrent.github.io/theft/articles/theft.html","id":"reading-and-processing-hctsa-formatted-files","dir":"Articles","previous_headings":"","what":"Reading and processing hctsa-formatted files","title":"Introduction to theft","text":"theft based foundations laid hctsa, also functionality reading hctsa-formatted Matlab files automatically processing tidy dataframes ready feature extraction theft. process_hctsa_file function takes string filepath Matlab file work , returning dataframe naming conventions consistent theft functionality. per hctsa specifications Input File Format 1, file 3 variables following exact names: timeSeriesData, labels, keywords. example using Bonn University EEG dataset3.","code":"d2 <- process_hctsa_file(\"https://cloudstor.aarnet.edu.au/plus/s/6sRD6IPMJyZLNlN/download\")"},{"path":"https://hendersontrent.github.io/theft/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Trent Henderson. Maintainer, author. Annie Bryant. Contributor.            Balanced classification accuracy","code":""},{"path":"https://hendersontrent.github.io/theft/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Henderson T (2022). theft: Tools Handling Extraction Features Time Series. R package version 0.3.9.7, https://hendersontrent.github.io/theft/.","code":"@Manual{,   title = {theft: Tools for Handling Extraction of Features from Time Series},   author = {Trent Henderson},   year = {2022},   note = {R package version 0.3.9.7},   url = {https://hendersontrent.github.io/theft/}, }"},{"path":"https://hendersontrent.github.io/theft/index.html","id":"theft-","dir":"","previous_headings":"","what":"Tools for Handling Extraction of Features from Time Series","title":"Tools for Handling Extraction of Features from Time Series","text":"Tools Handling Extraction Features Time series (theft)","code":""},{"path":"https://hendersontrent.github.io/theft/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Tools for Handling Extraction of Features from Time Series","text":"can install stable version theft CRAN: can install development version theft GitHub using following:","code":"install.packages(\"theft\") devtools::install_github(\"hendersontrent/theft\")"},{"path":"https://hendersontrent.github.io/theft/index.html","id":"general-purpose","dir":"","previous_headings":"","what":"General purpose","title":"Tools for Handling Extraction of Features from Time Series","text":"theft software package R facilitates user-friendly access structured analytical workflow extraction, analysis, visualisation time-series features. package provides single point access large number time-series features range existing R Python packages lets user specify groups () features calculate. packages theft currently ‘steals’ features include: catch22 (R; see Rcatch22 native implementation CRAN) feasts (R) tsfeatures (R) Kats (Python) tsfresh (Python) TSFEL (Python) Note Kats, tsfresh TSFEL Python packages. R package reticulate used call Python code uses packages applies within broader tidy data philosophy embodied theft. present, depending input time series, theft provides access >1300 features. Prior using theft (want use Kats, tsfresh TSFEL feature sets; R-based sets run fine) working Python installation download Kats using instructions located , tsfresh /TSFEL . comprehensive comparison six feature sets, please refer recent paper Empirical Evaluation Time-Series Feature Sets.","code":""},{"path":"https://hendersontrent.github.io/theft/index.html","id":"statistical-and-graphical-tools","dir":"","previous_headings":"","what":"Statistical and graphical tools","title":"Tools for Handling Extraction of Features from Time Series","text":"theft also contains extensive suite tools automatic processing extracted feature vectors (including data quality assessments normalisation methods), low dimensional projections (linear nonlinear), data matrix visualisations, single feature multiple feature time-series classification procedures, various statistical graphical tools.","code":""},{"path":"https://hendersontrent.github.io/theft/index.html","id":"web-application","dir":"","previous_headings":"","what":"Web application","title":"Tools for Handling Extraction of Features from Time Series","text":"interactive web application built top theft enables users access functionality included package within web browser without code. application automates entire workflow included theft, converts static graphics included package interactive visualisations, enables downloads feature calculations. Note since theft active development project, functionality copied across webtool yet.","code":""},{"path":"https://hendersontrent.github.io/theft/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Tools for Handling Extraction of Features from Time Series","text":"","code":"To cite package 'theft' in publications use:    Trent Henderson (2022). theft: Tools for Handling Extraction of   Features from Time Series. R package version 0.3.9.7.   https://hendersontrent.github.io/theft/  A BibTeX entry for LaTeX users is    @Manual{,     title = {theft: Tools for Handling Extraction of Features from Time Series},     author = {Trent Henderson},     year = {2022},     note = {R package version 0.3.9.7},     url = {https://hendersontrent.github.io/theft/},   }"},{"path":"https://hendersontrent.github.io/theft/reference/calculate_features.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute features on an input time series dataset — calculate_features","title":"Compute features on an input time series dataset — calculate_features","text":"Compute features input time series dataset","code":""},{"path":"https://hendersontrent.github.io/theft/reference/calculate_features.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute features on an input time series dataset — calculate_features","text":"","code":"calculate_features(   data,   id_var = NULL,   time_var = NULL,   values_var = NULL,   group_var = NULL,   feature_set = c(\"catch22\", \"feasts\", \"tsfeatures\", \"Kats\", \"tsfresh\", \"TSFEL\"),   catch24 = FALSE,   tsfresh_cleanup = FALSE,   seed = 123 )"},{"path":"https://hendersontrent.github.io/theft/reference/calculate_features.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute features on an input time series dataset — calculate_features","text":"data dataframe least 4 columns: id variable, group variable, time variable, value variable id_var string specifying ID variable identify time series. Defaults NULL time_var string specifying time index variable. Defaults NULL values_var string specifying values variable. Defaults NULL group_var string specifying grouping variable unique series sits (one exists). Defaults NULL feature_set set time-series features calculate. Defaults catch22 catch24 Boolean specifying whether compute catch24 addition catch22 catch22 one feature sets selected. Defaults FALSE tsfresh_cleanup Boolean specifying whether use -built tsfresh relevant feature filter . Defaults FALSE seed fixed number R's random number generator ensure reproducibility","code":""},{"path":"https://hendersontrent.github.io/theft/reference/calculate_features.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute features on an input time series dataset — calculate_features","text":"object class dataframe contains summary statistics feature","code":""},{"path":"https://hendersontrent.github.io/theft/reference/calculate_features.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute features on an input time series dataset — calculate_features","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theft/reference/calculate_features.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute features on an input time series dataset — calculate_features","text":"","code":"featMat <- calculate_features(data = simData,    id_var = \"id\",    time_var = \"timepoint\",    values_var = \"values\",    group_var = \"process\",    feature_set = \"catch22\",   seed = 123) #> No IDs removed. All value vectors good for feature extraction. #> Running computations for catch22... #> Warning: As of 0.1.14 the feature 'CO_f1ecac' returns a double instead of int #> This warning is displayed once per session. #>  #> Calculations completed for catch22."},{"path":"https://hendersontrent.github.io/theft/reference/check_vector_quality.html","id":null,"dir":"Reference","previous_headings":"","what":"Check data quality of a vector — check_vector_quality","title":"Check data quality of a vector — check_vector_quality","text":"Check data quality vector","code":""},{"path":"https://hendersontrent.github.io/theft/reference/check_vector_quality.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check data quality of a vector — check_vector_quality","text":"","code":"check_vector_quality(x)"},{"path":"https://hendersontrent.github.io/theft/reference/check_vector_quality.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check data quality of a vector — check_vector_quality","text":"x input data vector","code":""},{"path":"https://hendersontrent.github.io/theft/reference/check_vector_quality.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check data quality of a vector — check_vector_quality","text":"Boolean whether data good extract features ","code":""},{"path":"https://hendersontrent.github.io/theft/reference/check_vector_quality.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check data quality of a vector — check_vector_quality","text":"","code":"x <- stats::rnorm(10) check_vector_quality(x) #> [1] TRUE"},{"path":"https://hendersontrent.github.io/theft/reference/compute_top_features.html","id":null,"dir":"Reference","previous_headings":"","what":"Return an object containing results from top-performing features on a classification task — compute_top_features","title":"Return an object containing results from top-performing features on a classification task — compute_top_features","text":"Return object containing results top-performing features classification task","code":""},{"path":"https://hendersontrent.github.io/theft/reference/compute_top_features.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return an object containing results from top-performing features on a classification task — compute_top_features","text":"","code":"compute_top_features(   data,   id_var = \"id\",   group_var = \"group\",   num_features = 40,   normalise_violin_plots = FALSE,   method = c(\"z-score\", \"Sigmoid\", \"RobustSigmoid\", \"MinMax\"),   cor_method = c(\"pearson\", \"spearman\"),   test_method = \"gaussprRadial\",   clust_method = c(\"average\", \"ward.D\", \"ward.D2\", \"single\", \"complete\", \"mcquitty\",     \"median\", \"centroid\"),   use_balanced_accuracy = FALSE,   use_k_fold = FALSE,   num_folds = 10,   use_empirical_null = FALSE,   null_testing_method = c(\"ModelFreeShuffles\", \"NullModelFits\"),   p_value_method = c(\"empirical\", \"gaussian\"),   num_permutations = 50,   pool_empirical_null = FALSE,   seed = 123 )"},{"path":"https://hendersontrent.github.io/theft/reference/compute_top_features.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return an object containing results from top-performing features on a classification task — compute_top_features","text":"data dataframe containing raw feature matrix id_var string specifying ID variable group data (one exists). Defaults \"id\" group_var string specifying grouping variable data aggregates . Defaults \"group\" num_features number top features retain explore. Defaults 40 normalise_violin_plots Boolean whether normalise features plotting. Defaults FALSE method rescaling/normalising method apply. Defaults \"RobustSigmoid\" cor_method correlation method use. Defaults \"pearson\" test_method algorithm use quantifying class separation. Defaults \"gaussprRadial\" clust_method hierarchical clustering method use pairwise correlation plot. Defaults \"average\" use_balanced_accuracy Boolean specifying whether use balanced accuracy summary metric caret model training. Defaults FALSE use_k_fold Boolean specifying whether use k-fold procedures generating distribution classification accuracy estimates caret model specified test_method. Defaults  FALSE num_folds integer specifying number k-folds perform use_k_fold set TRUE. Defaults 10 use_empirical_null Boolean specifying whether use empirical null procedures compute p-values caret model specified test_method. Defaults FALSE null_testing_method string specifying type statistical method use calculate p-values. Defaults model free shuffles p_value_method string specifying method calculating p-values. Defaults \"empirical\" num_permutations integer specifying number class label shuffles perform use_empirical_null TRUE. Defaults 50 pool_empirical_null Boolean specifying whether use pooled empirical null distribution features features' individual empirical null distribution caret model specified test_method use_empirical_null TRUE. Defaults FALSE seed fixed number R's random number generator ensure reproducibility","code":""},{"path":"https://hendersontrent.github.io/theft/reference/compute_top_features.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return an object containing results from top-performing features on a classification task — compute_top_features","text":"object class list containing dataframe results, feature x feature matrix plot, violin plot","code":""},{"path":"https://hendersontrent.github.io/theft/reference/compute_top_features.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Return an object containing results from top-performing features on a classification task — compute_top_features","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theft/reference/compute_top_features.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Return an object containing results from top-performing features on a classification task — compute_top_features","text":"","code":"# \\donttest{ featMat <- calculate_features(data = simData,    id_var = \"id\",    time_var = \"timepoint\",    values_var = \"values\",    group_var = \"process\",    feature_set = \"catch22\",   seed = 123) #> No IDs removed. All value vectors good for feature extraction. #> Running computations for catch22... #>  #> Calculations completed for catch22.    compute_top_features(featMat,   id_var = \"id\",   group_var = \"group\",   num_features = 10,   normalise_violin_plots = FALSE,   method = \"RobustSigmoid\",   cor_method = \"pearson\",   test_method = \"gaussprRadial\",   clust_method = \"average\",   use_balanced_accuracy = FALSE,   use_k_fold = FALSE,   num_folds = 10,   use_empirical_null = TRUE,   null_testing_method = \"ModelFreeShuffles\",   p_value_method = \"gaussian\",   num_permutations = 100,   pool_empirical_null = FALSE,   seed = 123)  #> Null testing method 'ModelFreeShuffles' is fast. Consider running more permutations for more reliable results. N = 10000 is recommended. #> Null testing method 'ModelFreeShuffles' is fast. Consider running more permutations for more reliable results. N = 10000 is recommended. #> This will take a while. Great reason to go grab a coffee and relax ^_^ #>  #> Selecting top features using p-value. #> $ResultsTable #>                                         feature  accuracy p_value_accuracy #> 1      catch22_sp_summaries_welch_rect_area_5_1 0.9666667    2.837940e-170 #> 2      catch22_sp_summaries_welch_rect_centroid 0.8888889    3.530057e-139 #> 3                             catch22_co_f1ecac 0.8777778    5.382803e-135 #> 4          catch22_fc_local_simple_mean3_stderr 0.8277778    5.685461e-117 #> 5            catch22_sb_motif_three_quantile_hh 0.8000000    1.591674e-107 #> 6  catch22_co_embed2_dist_tau_d_expfit_meandiff 0.7444444     7.643036e-90 #> 7             catch22_co_histogram_ami_even_2_5 0.7055556     1.988011e-78 #> 8                       catch22_co_first_min_ac 0.7000000     7.320026e-77 #> 9     catch22_sb_binary_stats_mean_longstretch1 0.6555556     6.481323e-65 #> 10  catch22_sb_transition_matrix_3ac_sumdiagcov 0.6333333     2.498169e-59 #>    classifier_name               statistic_name #> 1    gaussprRadial Mean classification accuracy #> 2    gaussprRadial Mean classification accuracy #> 3    gaussprRadial Mean classification accuracy #> 4    gaussprRadial Mean classification accuracy #> 5    gaussprRadial Mean classification accuracy #> 6    gaussprRadial Mean classification accuracy #> 7    gaussprRadial Mean classification accuracy #> 8    gaussprRadial Mean classification accuracy #> 9    gaussprRadial Mean classification accuracy #> 10   gaussprRadial Mean classification accuracy #>  #> $FeatureFeatureCorrelationPlot  #>  #> $ViolinPlots  #>  # }"},{"path":"https://hendersontrent.github.io/theft/reference/feature_list.html","id":null,"dir":"Reference","previous_headings":"","what":"All features available in theft in tidy format — feature_list","title":"All features available in theft in tidy format — feature_list","text":"variables include:","code":""},{"path":"https://hendersontrent.github.io/theft/reference/feature_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"All features available in theft in tidy format — feature_list","text":"","code":"feature_list"},{"path":"https://hendersontrent.github.io/theft/reference/feature_list.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"All features available in theft in tidy format — feature_list","text":"tidy dataframe 2 variables: feature_set Name set feature feature Name feature","code":""},{"path":"https://hendersontrent.github.io/theft/reference/fit_multi_feature_classifier.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a classifier to feature matrix using all features or all features by set — fit_multi_feature_classifier","title":"Fit a classifier to feature matrix using all features or all features by set — fit_multi_feature_classifier","text":"Fit classifier feature matrix using features features set","code":""},{"path":"https://hendersontrent.github.io/theft/reference/fit_multi_feature_classifier.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a classifier to feature matrix using all features or all features by set — fit_multi_feature_classifier","text":"","code":"fit_multi_feature_classifier(   data,   id_var = \"id\",   group_var = \"group\",   by_set = FALSE,   test_method = \"gaussprRadial\",   use_balanced_accuracy = FALSE,   use_k_fold = TRUE,   num_folds = 10,   use_empirical_null = FALSE,   null_testing_method = c(\"ModelFreeShuffles\", \"NullModelFits\"),   p_value_method = c(\"empirical\", \"gaussian\"),   num_permutations = 100,   seed = 123 )"},{"path":"https://hendersontrent.github.io/theft/reference/fit_multi_feature_classifier.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit a classifier to feature matrix using all features or all features by set — fit_multi_feature_classifier","text":"data dataframe containing raw feature data calculated theft::calculate_features id_var string specifying ID variable group data (one exists). Defaults \"id\" group_var string specifying grouping variable data aggregates . Defaults \"group\" by_set Boolean specifying whether compute classifiers feature set. Defaults FALSE test_method algorithm use quantifying class separation. Defaults \"gaussprRadial\" use_balanced_accuracy Boolean specifying whether use balanced accuracy summary metric caret model training. Defaults FALSE use_k_fold Boolean specifying whether use k-fold procedures generating distribution classification accuracy estimates. Defaults TRUE num_folds integer specifying number folds (train-test splits) perform use_k_fold set TRUE. Defaults 10 use_empirical_null Boolean specifying whether use empirical null procedures compute p-values. Defaults FALSE null_testing_method string specifying type statistical method use calculate p-values. Defaults model free shuffles p_value_method string specifying method calculating p-values. Defaults \"empirical\" num_permutations integer specifying number class label shuffles perform use_empirical_null TRUE. Defaults 100 seed fixed number R's random number generator ensure reproducibility","code":""},{"path":"https://hendersontrent.github.io/theft/reference/fit_multi_feature_classifier.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit a classifier to feature matrix using all features or all features by set — fit_multi_feature_classifier","text":"object class list containing dataframe summaries classification models ggplot object by_set TRUE","code":""},{"path":"https://hendersontrent.github.io/theft/reference/fit_multi_feature_classifier.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fit a classifier to feature matrix using all features or all features by set — fit_multi_feature_classifier","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theft/reference/fit_multi_feature_classifier.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit a classifier to feature matrix using all features or all features by set — fit_multi_feature_classifier","text":"","code":"# \\donttest{ featMat <- calculate_features(data = simData,   id_var = \"id\",   time_var = \"timepoint\",   values_var = \"values\",   group_var = \"process\",   feature_set = \"catch22\",   seed = 123) #> No IDs removed. All value vectors good for feature extraction. #> Running computations for catch22... #>  #> Calculations completed for catch22.  fit_multi_feature_classifier(featMat,   id_var = \"id\",   group_var = \"group\",   by_set = FALSE,   test_method = \"gaussprRadial\",   use_balanced_accuracy = FALSE,   use_k_fold = TRUE,   num_folds = 10,   use_empirical_null = TRUE,   null_testing_method = \"ModelFreeShuffles\",   p_value_method = \"gaussian\",   num_permutations = 50,   seed = 123) #> Null testing method 'ModelFreeShuffles' is fast. Consider running more permutations for more reliable results. N = 10000 is recommended. #> Assessing feature values and unique IDs for NAs using matrix of all features. #> Loading required package: lattice #> Loading required package: ggplot2 #> $TestStatistics #>    accuracy p_value_accuracy classifier_name               statistic_name #> 1 0.8611111    1.721254e-113   gaussprRadial Mean classification accuracy #>  #> $RawClassificationResults #>     accuracy accuracy_sd category            method num_features_used #> 1  0.8611111   0.0539903     Main              <NA>                NA #> 2  0.1222222          NA     Null ModelFreeShuffles                NA #> 3  0.2277778          NA     Null ModelFreeShuffles                NA #> 4  0.1444444          NA     Null ModelFreeShuffles                NA #> 5  0.1444444          NA     Null ModelFreeShuffles                NA #> 6  0.1444444          NA     Null ModelFreeShuffles                NA #> 7  0.1777778          NA     Null ModelFreeShuffles                NA #> 8  0.1888889          NA     Null ModelFreeShuffles                NA #> 9  0.1777778          NA     Null ModelFreeShuffles                NA #> 10 0.1611111          NA     Null ModelFreeShuffles                NA #> 11 0.1277778          NA     Null ModelFreeShuffles                NA #> 12 0.1722222          NA     Null ModelFreeShuffles                NA #> 13 0.1611111          NA     Null ModelFreeShuffles                NA #> 14 0.1555556          NA     Null ModelFreeShuffles                NA #> 15 0.1555556          NA     Null ModelFreeShuffles                NA #> 16 0.2055556          NA     Null ModelFreeShuffles                NA #> 17 0.1944444          NA     Null ModelFreeShuffles                NA #> 18 0.1500000          NA     Null ModelFreeShuffles                NA #> 19 0.1777778          NA     Null ModelFreeShuffles                NA #> 20 0.1444444          NA     Null ModelFreeShuffles                NA #> 21 0.1500000          NA     Null ModelFreeShuffles                NA #> 22 0.1611111          NA     Null ModelFreeShuffles                NA #> 23 0.1277778          NA     Null ModelFreeShuffles                NA #> 24 0.1722222          NA     Null ModelFreeShuffles                NA #> 25 0.2333333          NA     Null ModelFreeShuffles                NA #> 26 0.2222222          NA     Null ModelFreeShuffles                NA #> 27 0.1777778          NA     Null ModelFreeShuffles                NA #> 28 0.2222222          NA     Null ModelFreeShuffles                NA #> 29 0.1611111          NA     Null ModelFreeShuffles                NA #> 30 0.2222222          NA     Null ModelFreeShuffles                NA #> 31 0.2111111          NA     Null ModelFreeShuffles                NA #> 32 0.1388889          NA     Null ModelFreeShuffles                NA #> 33 0.1388889          NA     Null ModelFreeShuffles                NA #> 34 0.1666667          NA     Null ModelFreeShuffles                NA #> 35 0.1833333          NA     Null ModelFreeShuffles                NA #> 36 0.1444444          NA     Null ModelFreeShuffles                NA #> 37 0.1500000          NA     Null ModelFreeShuffles                NA #> 38 0.1722222          NA     Null ModelFreeShuffles                NA #> 39 0.1888889          NA     Null ModelFreeShuffles                NA #> 40 0.1888889          NA     Null ModelFreeShuffles                NA #> 41 0.1722222          NA     Null ModelFreeShuffles                NA #> 42 0.1555556          NA     Null ModelFreeShuffles                NA #> 43 0.1555556          NA     Null ModelFreeShuffles                NA #> 44 0.1944444          NA     Null ModelFreeShuffles                NA #> 45 0.1555556          NA     Null ModelFreeShuffles                NA #> 46 0.1277778          NA     Null ModelFreeShuffles                NA #> 47 0.1444444          NA     Null ModelFreeShuffles                NA #> 48 0.1777778          NA     Null ModelFreeShuffles                NA #> 49 0.1833333          NA     Null ModelFreeShuffles                NA #> 50 0.2000000          NA     Null ModelFreeShuffles                NA #> 51 0.2555556          NA     Null ModelFreeShuffles                NA #>    classifier_name               statistic_name #> 1    gaussprRadial Mean classification accuracy #> 2    gaussprRadial Mean classification accuracy #> 3    gaussprRadial Mean classification accuracy #> 4    gaussprRadial Mean classification accuracy #> 5    gaussprRadial Mean classification accuracy #> 6    gaussprRadial Mean classification accuracy #> 7    gaussprRadial Mean classification accuracy #> 8    gaussprRadial Mean classification accuracy #> 9    gaussprRadial Mean classification accuracy #> 10   gaussprRadial Mean classification accuracy #> 11   gaussprRadial Mean classification accuracy #> 12   gaussprRadial Mean classification accuracy #> 13   gaussprRadial Mean classification accuracy #> 14   gaussprRadial Mean classification accuracy #> 15   gaussprRadial Mean classification accuracy #> 16   gaussprRadial Mean classification accuracy #> 17   gaussprRadial Mean classification accuracy #> 18   gaussprRadial Mean classification accuracy #> 19   gaussprRadial Mean classification accuracy #> 20   gaussprRadial Mean classification accuracy #> 21   gaussprRadial Mean classification accuracy #> 22   gaussprRadial Mean classification accuracy #> 23   gaussprRadial Mean classification accuracy #> 24   gaussprRadial Mean classification accuracy #> 25   gaussprRadial Mean classification accuracy #> 26   gaussprRadial Mean classification accuracy #> 27   gaussprRadial Mean classification accuracy #> 28   gaussprRadial Mean classification accuracy #> 29   gaussprRadial Mean classification accuracy #> 30   gaussprRadial Mean classification accuracy #> 31   gaussprRadial Mean classification accuracy #> 32   gaussprRadial Mean classification accuracy #> 33   gaussprRadial Mean classification accuracy #> 34   gaussprRadial Mean classification accuracy #> 35   gaussprRadial Mean classification accuracy #> 36   gaussprRadial Mean classification accuracy #> 37   gaussprRadial Mean classification accuracy #> 38   gaussprRadial Mean classification accuracy #> 39   gaussprRadial Mean classification accuracy #> 40   gaussprRadial Mean classification accuracy #> 41   gaussprRadial Mean classification accuracy #> 42   gaussprRadial Mean classification accuracy #> 43   gaussprRadial Mean classification accuracy #> 44   gaussprRadial Mean classification accuracy #> 45   gaussprRadial Mean classification accuracy #> 46   gaussprRadial Mean classification accuracy #> 47   gaussprRadial Mean classification accuracy #> 48   gaussprRadial Mean classification accuracy #> 49   gaussprRadial Mean classification accuracy #> 50   gaussprRadial Mean classification accuracy #> 51   gaussprRadial Mean classification accuracy #>  # }"},{"path":"https://hendersontrent.github.io/theft/reference/fit_multivariable_classifier.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a classifier to feature matrix using all features or all features by set — fit_multivariable_classifier","title":"Fit a classifier to feature matrix using all features or all features by set — fit_multivariable_classifier","text":"Fit classifier feature matrix using features features set","code":""},{"path":"https://hendersontrent.github.io/theft/reference/fit_multivariable_classifier.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a classifier to feature matrix using all features or all features by set — fit_multivariable_classifier","text":"","code":"fit_multivariable_classifier(   data,   id_var = \"id\",   group_var = \"group\",   by_set = FALSE,   test_method = \"gaussprRadial\",   use_balanced_accuracy = FALSE,   use_k_fold = TRUE,   num_folds = 10,   use_empirical_null = FALSE,   null_testing_method = c(\"model free shuffles\", \"null model fits\"),   p_value_method = c(\"empirical\", \"gaussian\"),   num_permutations = 100,   seed = 123 )"},{"path":"https://hendersontrent.github.io/theft/reference/fit_multivariable_classifier.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit a classifier to feature matrix using all features or all features by set — fit_multivariable_classifier","text":"data dataframe containing raw feature data calculated theft::calculate_features id_var string specifying ID variable group data (one exists). Defaults \"id\" group_var string specifying grouping variable data aggregates . Defaults \"group\" by_set Boolean specifying whether compute classifiers feature set. Defaults FALSE test_method algorithm use quantifying class separation. Defaults \"gaussprRadial\" use_balanced_accuracy Boolean specifying whether use balanced accuracy summary metric caret model training. Defaults FALSE use_k_fold Boolean specifying whether use k-fold procedures generating distribution classification accuracy estimates. Defaults TRUE num_folds integer specifying number folds (train-test splits) perform use_k_fold set TRUE. Defaults 10 use_empirical_null Boolean specifying whether use empirical null procedures compute p-values. Defaults FALSE null_testing_method string specifying type statistical method use calculate p-values. Defaults model free shuffles p_value_method string specifying method calculating p-values. Defaults \"empirical\" num_permutations integer specifying number class label shuffles perform use_empirical_null TRUE. Defaults 100 seed fixed number R's random number generator ensure reproducibility","code":""},{"path":"https://hendersontrent.github.io/theft/reference/fit_multivariable_classifier.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit a classifier to feature matrix using all features or all features by set — fit_multivariable_classifier","text":"object class list containing dataframe summaries classification models ggplot object by_set TRUE","code":""},{"path":"https://hendersontrent.github.io/theft/reference/fit_multivariable_classifier.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fit a classifier to feature matrix using all features or all features by set — fit_multivariable_classifier","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theft/reference/fit_multivariable_classifier.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit a classifier to feature matrix using all features or all features by set — fit_multivariable_classifier","text":"","code":"if (FALSE) { featMat <- calculate_features(data = simData,   id_var = \"id\",   time_var = \"timepoint\",   values_var = \"values\",   group_var = \"process\",   feature_set = \"catch22\")  fit_multivariable_classifier(featMat,   id_var = \"id\",   group_var = \"group\",   by_set = FALSE,   test_method = \"gaussprRadial\",   use_balanced_accuracy = FALSE,   use_k_fold = TRUE,   num_folds = 10,   use_empirical_null = TRUE,   null_testing_method = \"model free shuffles\",   p_value_method = \"empirical\",   num_permutations = 100,   seed = 123) }"},{"path":"https://hendersontrent.github.io/theft/reference/fit_single_feature_classifier.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a classifier to feature matrix to extract top performers — fit_single_feature_classifier","title":"Fit a classifier to feature matrix to extract top performers — fit_single_feature_classifier","text":"Fit classifier feature matrix extract top performers","code":""},{"path":"https://hendersontrent.github.io/theft/reference/fit_single_feature_classifier.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a classifier to feature matrix to extract top performers — fit_single_feature_classifier","text":"","code":"fit_single_feature_classifier(   data,   id_var = \"id\",   group_var = \"group\",   test_method = \"gaussprRadial\",   use_balanced_accuracy = FALSE,   use_k_fold = FALSE,   num_folds = 10,   use_empirical_null = FALSE,   null_testing_method = c(\"ModelFreeShuffles\", \"NullModelFits\"),   p_value_method = c(\"empirical\", \"gaussian\"),   num_permutations = 50,   pool_empirical_null = FALSE,   seed = 123,   return_raw_estimates = FALSE )"},{"path":"https://hendersontrent.github.io/theft/reference/fit_single_feature_classifier.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit a classifier to feature matrix to extract top performers — fit_single_feature_classifier","text":"data dataframe containing raw feature matrix id_var string specifying ID variable group data (one exists). Defaults \"id\" group_var string specifying grouping variable data aggregates . Defaults \"group\" test_method algorithm use quantifying class separation. Defaults \"gaussprRadial\". either \"t-test\", \"wilcox\", \"binomial logistic\" two-class problems obtain exact statistics, valid caret classification model everything else use_balanced_accuracy Boolean specifying whether use balanced accuracy summary metric caret model training. Defaults FALSE use_k_fold Boolean specifying whether use k-fold procedures generating distribution classification accuracy estimates caret model specified test_method. Defaults  FALSE num_folds integer specifying number k-folds perform use_k_fold set TRUE. Defaults 10 use_empirical_null Boolean specifying whether use empirical null procedures compute p-values caret model specified test_method. Defaults FALSE null_testing_method string specifying type statistical method use calculate p-values. Defaults model free shuffles p_value_method string specifying method calculating p-values. Defaults \"empirical\" num_permutations integer specifying number class label shuffles perform use_empirical_null TRUE. Defaults 50 pool_empirical_null Boolean specifying whether use pooled empirical null distribution features features' individual empirical null distribution caret model specified test_method use_empirical_null TRUE. Defaults FALSE seed fixed number R's random number generator ensure reproducibility return_raw_estimates Boolean (testing purposes -- break compute_top_features!!) specifying whether return raw main null model results","code":""},{"path":"https://hendersontrent.github.io/theft/reference/fit_single_feature_classifier.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit a classifier to feature matrix to extract top performers — fit_single_feature_classifier","text":"object class dataframe containing results","code":""},{"path":"https://hendersontrent.github.io/theft/reference/fit_single_feature_classifier.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fit a classifier to feature matrix to extract top performers — fit_single_feature_classifier","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theft/reference/fit_single_feature_classifier.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit a classifier to feature matrix to extract top performers — fit_single_feature_classifier","text":"","code":"# \\donttest{ featMat <- calculate_features(data = simData,    id_var = \"id\",    time_var = \"timepoint\",    values_var = \"values\",    group_var = \"process\",    feature_set = \"catch22\",   seed = 123) #> No IDs removed. All value vectors good for feature extraction. #> Running computations for catch22... #>  #> Calculations completed for catch22.    # Mimic machinery of theft::compute_top_features # which calls fit_single_feature_classifier and # does these operations prior    featMat$group <- make.names(featMat$group) featMat$group <- as.factor(featMat$group) featMat$values <- as.numeric(featMat$values)    fit_single_feature_classifier(featMat,   id_var = \"id\",   group_var = \"group\",   test_method = \"gaussprRadial\",   use_balanced_accuracy = FALSE,   use_k_fold = TRUE,   num_folds = 10,   use_empirical_null = TRUE,   null_testing_method = \"ModelFreeShuffles\",   p_value_method = \"gaussian\",   num_permutations = 50,   pool_empirical_null = FALSE,   seed = 123,   return_raw_estimates = FALSE)  #> Null testing method 'ModelFreeShuffles' is fast. Consider running more permutations for more reliable results. N = 10000 is recommended. #> This will take a while. Great reason to go grab a coffee and relax ^_^ #>                                                 feature  accuracy #> 1                           catch22_dn_histogram_mode_5 0.3611111 #> 2                          catch22_dn_histogram_mode_10 0.3111111 #> 3                                     catch22_co_f1ecac 0.7888889 #> 4                               catch22_co_first_min_ac 0.6666667 #> 5                     catch22_co_histogram_ami_even_2_5 0.6722222 #> 6                                 catch22_co_trev_1_num 0.4388889 #> 7                          catch22_md_hrv_classic_pnn40 0.4333333 #> 8             catch22_sb_binary_stats_mean_longstretch1 0.6388889 #> 9           catch22_sb_transition_matrix_3ac_sumdiagcov 0.5333333 #> 10                   catch22_pd_periodicity_wang_th0_01 0.5111111 #> 11         catch22_co_embed2_dist_tau_d_expfit_meandiff 0.6944444 #> 12   catch22_in_auto_mutual_info_stats_40_gaussian_fmmi 0.5333333 #> 13              catch22_fc_local_simple_mean1_tauresrat 0.6222222 #> 14               catch22_dn_outlier_include_p_001_mdrmd 0.3222222 #> 15               catch22_dn_outlier_include_n_001_mdrmd 0.3555556 #> 16             catch22_sp_summaries_welch_rect_area_5_1 0.9500000 #> 17            catch22_sb_binary_stats_diff_longstretch0 0.4333333 #> 18                   catch22_sb_motif_three_quantile_hh 0.7777778 #> 19 catch22_sc_fluct_anal_2_rsrangefit_50_1_logi_prop_r1 0.2722222 #> 20      catch22_sc_fluct_anal_2_dfa_50_1_2_logi_prop_r1 0.2500000 #> 21             catch22_sp_summaries_welch_rect_centroid 0.8722222 #> 22                 catch22_fc_local_simple_mean3_stderr 0.8222222 #>    p_value_accuracy classifier_name               statistic_name #> 1      2.646837e-10   gaussprRadial Mean classification accuracy #> 2      2.436996e-06   gaussprRadial Mean classification accuracy #> 3      2.120380e-91   gaussprRadial Mean classification accuracy #> 4      1.488492e-59   gaussprRadial Mean classification accuracy #> 5      7.518342e-61   gaussprRadial Mean classification accuracy #> 6      9.654280e-19   gaussprRadial Mean classification accuracy #> 7      4.783652e-18   gaussprRadial Mean classification accuracy #> 8      2.756663e-53   gaussprRadial Mean classification accuracy #> 9      9.659005e-33   gaussprRadial Mean classification accuracy #> 10     4.474297e-29   gaussprRadial Mean classification accuracy #> 11     3.515038e-66   gaussprRadial Mean classification accuracy #> 12     9.659005e-33   gaussprRadial Mean classification accuracy #> 13     1.068134e-49   gaussprRadial Mean classification accuracy #> 14     4.016075e-07   gaussprRadial Mean classification accuracy #> 15     8.304186e-10   gaussprRadial Mean classification accuracy #> 16    5.107928e-144   gaussprRadial Mean classification accuracy #> 17     4.783652e-18   gaussprRadial Mean classification accuracy #> 18     3.229540e-88   gaussprRadial Mean classification accuracy #> 19     4.928403e-04   gaussprRadial Mean classification accuracy #> 20     5.148504e-03   gaussprRadial Mean classification accuracy #> 21    4.182436e-117   gaussprRadial Mean classification accuracy #> 22    2.709871e-101   gaussprRadial Mean classification accuracy # }"},{"path":"https://hendersontrent.github.io/theft/reference/fit_univariable_classifier.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a classifier to feature matrix to extract top performers — fit_univariable_classifier","title":"Fit a classifier to feature matrix to extract top performers — fit_univariable_classifier","text":"Fit classifier feature matrix extract top performers","code":""},{"path":"https://hendersontrent.github.io/theft/reference/fit_univariable_classifier.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a classifier to feature matrix to extract top performers — fit_univariable_classifier","text":"","code":"fit_univariable_classifier(   data,   id_var = \"id\",   group_var = \"group\",   test_method = \"gaussprRadial\",   use_balanced_accuracy = FALSE,   use_k_fold = FALSE,   num_folds = 10,   use_empirical_null = FALSE,   null_testing_method = c(\"model free shuffles\", \"null model fits\"),   p_value_method = c(\"empirical\", \"gaussian\"),   num_permutations = 50,   pool_empirical_null = FALSE,   seed = 123,   return_raw_estimates = FALSE )"},{"path":"https://hendersontrent.github.io/theft/reference/fit_univariable_classifier.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit a classifier to feature matrix to extract top performers — fit_univariable_classifier","text":"data dataframe containing raw feature matrix id_var string specifying ID variable group data (one exists). Defaults \"id\" group_var string specifying grouping variable data aggregates . Defaults \"group\" test_method algorithm use quantifying class separation. Defaults \"gaussprRadial\". either \"t-test\", \"wilcox\", \"binomial logistic\" two-class problems obtain exact statistics, valid caret classification model everything else use_balanced_accuracy Boolean specifying whether use balanced accuracy summary metric caret model training. Defaults FALSE use_k_fold Boolean specifying whether use k-fold procedures generating distribution classification accuracy estimates caret model specified test_method. Defaults  FALSE num_folds integer specifying number k-folds perform use_k_fold set TRUE. Defaults 10 use_empirical_null Boolean specifying whether use empirical null procedures compute p-values caret model specified test_method. Defaults FALSE null_testing_method string specifying type statistical method use calculate p-values. Defaults model free shuffles p_value_method string specifying method calculating p-values. Defaults \"empirical\" num_permutations integer specifying number class label shuffles perform use_empirical_null TRUE. Defaults 50 pool_empirical_null Boolean specifying whether use pooled empirical null distribution features features' individual empirical null distribution caret model specified test_method use_empirical_null TRUE. Defaults FALSE seed fixed number R's random number generator ensure reproducibility return_raw_estimates Boolean (testing purposes -- break compute_top_features!!) specifying whether return raw main null model results","code":""},{"path":"https://hendersontrent.github.io/theft/reference/fit_univariable_classifier.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit a classifier to feature matrix to extract top performers — fit_univariable_classifier","text":"object class dataframe containing results","code":""},{"path":"https://hendersontrent.github.io/theft/reference/fit_univariable_classifier.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fit a classifier to feature matrix to extract top performers — fit_univariable_classifier","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theft/reference/fit_univariable_classifier.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit a classifier to feature matrix to extract top performers — fit_univariable_classifier","text":"","code":"if (FALSE) { featMat <- calculate_features(data = simData,    id_var = \"id\",    time_var = \"timepoint\",    values_var = \"values\",    group_var = \"process\",    feature_set = \"catch22\")    fit_univariable_classifier(featMat,   id_var = \"id\",   group_var = \"group\",   test_method = \"linear svm\",   use_balanced_accuracy = FALSE,   use_k_fold = TRUE,   num_folds = 10,   use_empirical_null = TRUE,   null_testing_method = \"model free shuffles\",   p_value_method = \"empirical\",   num_permutations = 50,   pool_empirical_null = FALSE,   seed = 123,   return_raw_estimates = FALSE)  }"},{"path":"https://hendersontrent.github.io/theft/reference/init_theft.html","id":null,"dir":"Reference","previous_headings":"","what":"Communicate to R the correct Python version containing the relevant libraries for calculating features — init_theft","title":"Communicate to R the correct Python version containing the relevant libraries for calculating features — init_theft","text":"Communicate R correct Python version containing relevant libraries calculating features","code":""},{"path":"https://hendersontrent.github.io/theft/reference/init_theft.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Communicate to R the correct Python version containing the relevant libraries for calculating features — init_theft","text":"","code":"init_theft(path_to_python)"},{"path":"https://hendersontrent.github.io/theft/reference/init_theft.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Communicate to R the correct Python version containing the relevant libraries for calculating features — init_theft","text":"path_to_python string specifying filepath version Python containing relevant libraries calculating features","code":""},{"path":"https://hendersontrent.github.io/theft/reference/init_theft.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Communicate to R the correct Python version containing the relevant libraries for calculating features — init_theft","text":"return value; called side effects","code":""},{"path":"https://hendersontrent.github.io/theft/reference/init_theft.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Communicate to R the correct Python version containing the relevant libraries for calculating features — init_theft","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theft/reference/init_theft.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Communicate to R the correct Python version containing the relevant libraries for calculating features — init_theft","text":"","code":"# \\donttest{ init_theft(\"~/opt/anaconda3/bin/python\") # }"},{"path":"https://hendersontrent.github.io/theft/reference/minmax_scaler.html","id":null,"dir":"Reference","previous_headings":"","what":"This function rescales a vector of numerical values into the unit interval [0,1] — minmax_scaler","title":"This function rescales a vector of numerical values into the unit interval [0,1] — minmax_scaler","text":"function rescales vector numerical values unit interval [0,1]","code":""},{"path":"https://hendersontrent.github.io/theft/reference/minmax_scaler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"This function rescales a vector of numerical values into the unit interval [0,1] — minmax_scaler","text":"","code":"minmax_scaler(x)"},{"path":"https://hendersontrent.github.io/theft/reference/minmax_scaler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"This function rescales a vector of numerical values into the unit interval [0,1] — minmax_scaler","text":"x numeric vector, preferably feature values computed theft package functions","code":""},{"path":"https://hendersontrent.github.io/theft/reference/minmax_scaler.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"This function rescales a vector of numerical values into the unit interval [0,1] — minmax_scaler","text":"x numeric vector, rescaled [0,1] unit interval","code":""},{"path":"https://hendersontrent.github.io/theft/reference/minmax_scaler.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"This function rescales a vector of numerical values into the unit interval [0,1] — minmax_scaler","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theft/reference/minmax_scaler.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"This function rescales a vector of numerical values into the unit interval [0,1] — minmax_scaler","text":"","code":"minmax_scaler(stats::rnorm(10)) #>  [1] 0.06751382 0.40553812 0.46214123 0.86447157 0.72530486 0.38982701 #>  [7] 1.00000000 0.39208730 0.70974735 0.00000000"},{"path":"https://hendersontrent.github.io/theft/reference/normalise_feature_frame.html","id":null,"dir":"Reference","previous_headings":"","what":"Scale each feature vector into a user-specified range for visualisation and modelling — normalise_feature_frame","title":"Scale each feature vector into a user-specified range for visualisation and modelling — normalise_feature_frame","text":"Scale feature vector user-specified range visualisation modelling","code":""},{"path":"https://hendersontrent.github.io/theft/reference/normalise_feature_frame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scale each feature vector into a user-specified range for visualisation and modelling — normalise_feature_frame","text":"","code":"normalise_feature_frame(   data,   names_var = \"names\",   values_var = \"values\",   method = c(\"z-score\", \"Sigmoid\", \"RobustSigmoid\", \"MinMax\") )"},{"path":"https://hendersontrent.github.io/theft/reference/normalise_feature_frame.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scale each feature vector into a user-specified range for visualisation and modelling — normalise_feature_frame","text":"data dataframe least 2 columns: names variable (feature names) value variable names_var string denoting name variable/column holds feature names. Defaults \"names\" values_var string denoting name variable/column holds numerical feature values. Defaults \"values\" method rescaling/normalising method apply. Defaults \"RobustSigmoid\"","code":""},{"path":"https://hendersontrent.github.io/theft/reference/normalise_feature_frame.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scale each feature vector into a user-specified range for visualisation and modelling — normalise_feature_frame","text":"dataframe value column rescaled specified range","code":""},{"path":"https://hendersontrent.github.io/theft/reference/normalise_feature_frame.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Scale each feature vector into a user-specified range for visualisation and modelling — normalise_feature_frame","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theft/reference/normalise_feature_frame.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Scale each feature vector into a user-specified range for visualisation and modelling — normalise_feature_frame","text":"","code":"featMat <- calculate_features(data = simData,    id_var = \"id\",    time_var = \"timepoint\",    values_var = \"values\",    group_var = \"process\",    feature_set = \"catch22\",   seed = 123) #> No IDs removed. All value vectors good for feature extraction. #> Running computations for catch22... #>  #> Calculations completed for catch22.    normed <- normalise_feature_frame(featMat,    names_var = \"names\",    values_var = \"values\",    method = \"RobustSigmoid\")"},{"path":"https://hendersontrent.github.io/theft/reference/normalise_feature_vector.html","id":null,"dir":"Reference","previous_headings":"","what":"Scale each value into a user-specified range for visualisation and analysis — normalise_feature_vector","title":"Scale each value into a user-specified range for visualisation and analysis — normalise_feature_vector","text":"Scale value user-specified range visualisation analysis","code":""},{"path":"https://hendersontrent.github.io/theft/reference/normalise_feature_vector.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scale each value into a user-specified range for visualisation and analysis — normalise_feature_vector","text":"","code":"normalise_feature_vector(   x,   method = c(\"z-score\", \"Sigmoid\", \"RobustSigmoid\", \"MinMax\") )"},{"path":"https://hendersontrent.github.io/theft/reference/normalise_feature_vector.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scale each value into a user-specified range for visualisation and analysis — normalise_feature_vector","text":"x vector scalar values method rescaling/normalising method apply. Defaults \"RobustSigmoid\"","code":""},{"path":"https://hendersontrent.github.io/theft/reference/normalise_feature_vector.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scale each value into a user-specified range for visualisation and analysis — normalise_feature_vector","text":"vector scalar values normalised selected range","code":""},{"path":"https://hendersontrent.github.io/theft/reference/normalise_feature_vector.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Scale each value into a user-specified range for visualisation and analysis — normalise_feature_vector","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theft/reference/normalise_feature_vector.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Scale each value into a user-specified range for visualisation and analysis — normalise_feature_vector","text":"","code":"featMat <- calculate_features(data = simData,    id_var = \"id\",    time_var = \"timepoint\",    values_var = \"values\",    group_var = \"process\",    feature_set = \"catch22\",   seed = 123) #> No IDs removed. All value vectors good for feature extraction. #> Running computations for catch22... #>  #> Calculations completed for catch22.    x <- featMat[featMat$names == \"DN_HistogramMode_5\", ] xnormed <- normalise_feature_vector(x$values, method = \"RobustSigmoid\")"},{"path":"https://hendersontrent.github.io/theft/reference/normalize_feature_frame.html","id":null,"dir":"Reference","previous_headings":"","what":"Scale each feature vector into a user-specified range for visualisation and modelling — normalize_feature_frame","title":"Scale each feature vector into a user-specified range for visualisation and modelling — normalize_feature_frame","text":"Scale feature vector user-specified range visualisation modelling","code":""},{"path":"https://hendersontrent.github.io/theft/reference/normalize_feature_frame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scale each feature vector into a user-specified range for visualisation and modelling — normalize_feature_frame","text":"","code":"normalize_feature_frame(   data,   names_var = \"names\",   values_var = \"values\",   method = c(\"z-score\", \"Sigmoid\", \"RobustSigmoid\", \"MinMax\") )"},{"path":"https://hendersontrent.github.io/theft/reference/normalize_feature_frame.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scale each feature vector into a user-specified range for visualisation and modelling — normalize_feature_frame","text":"data dataframe least 2 columns: names variable (feature names) value variable names_var string denoting name variable/column holds feature names. Defaults \"names\" values_var string denoting name variable/column holds numerical feature values. Defaults \"values\" method rescaling/normalising method apply. Defaults \"RobustSigmoid\"","code":""},{"path":"https://hendersontrent.github.io/theft/reference/normalize_feature_frame.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scale each feature vector into a user-specified range for visualisation and modelling — normalize_feature_frame","text":"dataframe value column rescaled specified range","code":""},{"path":"https://hendersontrent.github.io/theft/reference/normalize_feature_frame.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Scale each feature vector into a user-specified range for visualisation and modelling — normalize_feature_frame","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theft/reference/normalize_feature_frame.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Scale each feature vector into a user-specified range for visualisation and modelling — normalize_feature_frame","text":"","code":"featMat <- calculate_features(data = simData,    id_var = \"id\",    time_var = \"timepoint\",    values_var = \"values\",    group_var = \"process\",    feature_set = \"catch22\",   seed = 123) #> No IDs removed. All value vectors good for feature extraction. #> Running computations for catch22... #>  #> Calculations completed for catch22.    normed <- normalize_feature_frame(featMat,    names_var = \"names\",    values_var = \"values\",    method = \"RobustSigmoid\")"},{"path":"https://hendersontrent.github.io/theft/reference/normalize_feature_vector.html","id":null,"dir":"Reference","previous_headings":"","what":"Scale each value into a user-specified range for visualisation and analysis — normalize_feature_vector","title":"Scale each value into a user-specified range for visualisation and analysis — normalize_feature_vector","text":"Scale value user-specified range visualisation analysis","code":""},{"path":"https://hendersontrent.github.io/theft/reference/normalize_feature_vector.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scale each value into a user-specified range for visualisation and analysis — normalize_feature_vector","text":"","code":"normalize_feature_vector(   x,   method = c(\"z-score\", \"Sigmoid\", \"RobustSigmoid\", \"MinMax\") )"},{"path":"https://hendersontrent.github.io/theft/reference/normalize_feature_vector.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scale each value into a user-specified range for visualisation and analysis — normalize_feature_vector","text":"x vector scalar values method rescaling/normalising method apply. Defaults \"RobustSigmoid\"","code":""},{"path":"https://hendersontrent.github.io/theft/reference/normalize_feature_vector.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scale each value into a user-specified range for visualisation and analysis — normalize_feature_vector","text":"vector scalar values normalised selected range","code":""},{"path":"https://hendersontrent.github.io/theft/reference/normalize_feature_vector.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Scale each value into a user-specified range for visualisation and analysis — normalize_feature_vector","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theft/reference/normalize_feature_vector.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Scale each value into a user-specified range for visualisation and analysis — normalize_feature_vector","text":"","code":"featMat <- calculate_features(data = simData,    id_var = \"id\",    time_var = \"timepoint\",    values_var = \"values\",    group_var = \"process\",    feature_set = \"catch22\",   seed = 123) #> No IDs removed. All value vectors good for feature extraction. #> Running computations for catch22... #>  #> Calculations completed for catch22.    x <- featMat[featMat$names == \"DN_HistogramMode_5\", ] xnormed <- normalise_feature_vector(x$values, method = \"RobustSigmoid\")"},{"path":"https://hendersontrent.github.io/theft/reference/plot_all_features.html","id":null,"dir":"Reference","previous_headings":"","what":"Produce a heatmap matrix of the calculated feature value vectors and each unique time series with automatic hierarchical clustering. — plot_all_features","title":"Produce a heatmap matrix of the calculated feature value vectors and each unique time series with automatic hierarchical clustering. — plot_all_features","text":"Produce heatmap matrix calculated feature value vectors unique time series automatic hierarchical clustering.","code":""},{"path":"https://hendersontrent.github.io/theft/reference/plot_all_features.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Produce a heatmap matrix of the calculated feature value vectors and each unique time series with automatic hierarchical clustering. — plot_all_features","text":"","code":"plot_all_features(   data,   is_normalised = FALSE,   id_var = \"id\",   method = c(\"z-score\", \"Sigmoid\", \"RobustSigmoid\", \"MinMax\"),   clust_method = c(\"average\", \"ward.D\", \"ward.D2\", \"single\", \"complete\", \"mcquitty\",     \"median\", \"centroid\"),   interactive = FALSE )"},{"path":"https://hendersontrent.github.io/theft/reference/plot_all_features.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Produce a heatmap matrix of the calculated feature value vectors and each unique time series with automatic hierarchical clustering. — plot_all_features","text":"data dataframe least 2 columns called \"names\" \"values\" is_normalised Boolean whether input feature values already scaled. Defaults FALSE id_var string specifying ID variable identify time series. Defaults \"id\" method rescaling/normalising method apply. Defaults \"RobustSigmoid\" clust_method hierarchical clustering method use pairwise correlation plot. Defaults \"average\" interactive Boolean whether plot interactive plotly graphic. Defaults FALSE","code":""},{"path":"https://hendersontrent.github.io/theft/reference/plot_all_features.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Produce a heatmap matrix of the calculated feature value vectors and each unique time series with automatic hierarchical clustering. — plot_all_features","text":"object class ggplot contains heatmap graphic","code":""},{"path":"https://hendersontrent.github.io/theft/reference/plot_all_features.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Produce a heatmap matrix of the calculated feature value vectors and each unique time series with automatic hierarchical clustering. — plot_all_features","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theft/reference/plot_all_features.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Produce a heatmap matrix of the calculated feature value vectors and each unique time series with automatic hierarchical clustering. — plot_all_features","text":"","code":"featMat <- calculate_features(data = simData,    id_var = \"id\",    time_var = \"timepoint\",    values_var = \"values\",    group_var = \"process\",    feature_set = \"catch22\",   seed = 123) #> No IDs removed. All value vectors good for feature extraction. #> Running computations for catch22... #>  #> Calculations completed for catch22.  plot_all_features(featMat,    is_normalised = FALSE,    id_var = \"id\",    method = \"RobustSigmoid\",   clust_method = \"average\",   interactive = FALSE)"},{"path":"https://hendersontrent.github.io/theft/reference/plot_feature_correlations.html","id":null,"dir":"Reference","previous_headings":"","what":"Produce a correlation matrix plot showing pairwise correlations of feature vectors by unique id with automatic hierarchical clustering. — plot_feature_correlations","title":"Produce a correlation matrix plot showing pairwise correlations of feature vectors by unique id with automatic hierarchical clustering. — plot_feature_correlations","text":"Produce correlation matrix plot showing pairwise correlations feature vectors unique id automatic hierarchical clustering.","code":""},{"path":"https://hendersontrent.github.io/theft/reference/plot_feature_correlations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Produce a correlation matrix plot showing pairwise correlations of feature vectors by unique id with automatic hierarchical clustering. — plot_feature_correlations","text":"","code":"plot_feature_correlations(   data,   is_normalised = FALSE,   id_var = \"id\",   names_var = \"names\",   values_var = \"values\",   method = c(\"z-score\", \"Sigmoid\", \"RobustSigmoid\", \"MinMax\"),   cor_method = c(\"pearson\", \"spearman\"),   clust_method = c(\"average\", \"ward.D\", \"ward.D2\", \"single\", \"complete\", \"mcquitty\",     \"median\", \"centroid\"),   interactive = FALSE )"},{"path":"https://hendersontrent.github.io/theft/reference/plot_feature_correlations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Produce a correlation matrix plot showing pairwise correlations of feature vectors by unique id with automatic hierarchical clustering. — plot_feature_correlations","text":"data dataframe least 3 columns 'id', 'names' 'values' is_normalised Boolean whether input feature values already scaled. Defaults FALSE id_var string specifying ID variable compute pairwise correlations . Defaults \"id\" names_var string denoting name variable/column holds feature names. Defaults \"names\" values_var string denoting name variable/column holds numerical feature values. Defaults \"values\" method rescaling/normalising method apply. Defaults \"RobustSigmoid\" cor_method correlation method use. Defaults \"pearson\" clust_method hierarchical clustering method use pairwise correlation plot. Defaults \"average\" interactive Boolean whether plot interactive plotly graphic. Defaults FALSE","code":""},{"path":"https://hendersontrent.github.io/theft/reference/plot_feature_correlations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Produce a correlation matrix plot showing pairwise correlations of feature vectors by unique id with automatic hierarchical clustering. — plot_feature_correlations","text":"object class ggplot contains correlation matrix graphic","code":""},{"path":"https://hendersontrent.github.io/theft/reference/plot_feature_correlations.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Produce a correlation matrix plot showing pairwise correlations of feature vectors by unique id with automatic hierarchical clustering. — plot_feature_correlations","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theft/reference/plot_feature_correlations.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Produce a correlation matrix plot showing pairwise correlations of feature vectors by unique id with automatic hierarchical clustering. — plot_feature_correlations","text":"","code":"featMat <- calculate_features(data = simData,    id_var = \"id\",    time_var = \"timepoint\",    values_var = \"values\",    group_var = \"process\",    feature_set = \"catch22\",   seed = 123) #> No IDs removed. All value vectors good for feature extraction. #> Running computations for catch22... #>  #> Calculations completed for catch22.    plot_feature_correlations(data = featMat,    is_normalised = FALSE,    id_var = \"id\",    names_var = \"names\",    values_var = \"values\",   method = \"RobustSigmoid\",   cor_method = \"pearson\",   clust_method = \"average\",   interactive = FALSE)"},{"path":"https://hendersontrent.github.io/theft/reference/plot_feature_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Produce a heatmap matrix of the calculated feature value vectors and each unique time series with automatic hierarchical clustering. — plot_feature_matrix","title":"Produce a heatmap matrix of the calculated feature value vectors and each unique time series with automatic hierarchical clustering. — plot_feature_matrix","text":"Produce heatmap matrix calculated feature value vectors unique time series automatic hierarchical clustering.","code":""},{"path":"https://hendersontrent.github.io/theft/reference/plot_feature_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Produce a heatmap matrix of the calculated feature value vectors and each unique time series with automatic hierarchical clustering. — plot_feature_matrix","text":"","code":"plot_feature_matrix(   data,   is_normalised = FALSE,   id_var = \"id\",   method = c(\"z-score\", \"Sigmoid\", \"RobustSigmoid\", \"MinMax\"),   clust_method = c(\"average\", \"ward.D\", \"ward.D2\", \"single\", \"complete\", \"mcquitty\",     \"median\", \"centroid\"),   interactive = FALSE )"},{"path":"https://hendersontrent.github.io/theft/reference/plot_feature_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Produce a heatmap matrix of the calculated feature value vectors and each unique time series with automatic hierarchical clustering. — plot_feature_matrix","text":"data dataframe least 2 columns called \"names\" \"values\" is_normalised Boolean whether input feature values already scaled. Defaults FALSE id_var string specifying ID variable identify time series. Defaults \"id\" method rescaling/normalising method apply. Defaults \"RobustSigmoid\" clust_method hierarchical clustering method use pairwise correlation plot. Defaults \"average\" interactive Boolean whether plot interactive plotly graphic. Defaults FALSE","code":""},{"path":"https://hendersontrent.github.io/theft/reference/plot_feature_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Produce a heatmap matrix of the calculated feature value vectors and each unique time series with automatic hierarchical clustering. — plot_feature_matrix","text":"object class ggplot contains heatmap graphic","code":""},{"path":"https://hendersontrent.github.io/theft/reference/plot_feature_matrix.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Produce a heatmap matrix of the calculated feature value vectors and each unique time series with automatic hierarchical clustering. — plot_feature_matrix","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theft/reference/plot_feature_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Produce a heatmap matrix of the calculated feature value vectors and each unique time series with automatic hierarchical clustering. — plot_feature_matrix","text":"","code":"featMat <- calculate_features(data = simData,    id_var = \"id\",    time_var = \"timepoint\",    values_var = \"values\",    group_var = \"process\",    feature_set = \"catch22\",   seed = 123) #> No IDs removed. All value vectors good for feature extraction. #> Running computations for catch22... #>  #> Calculations completed for catch22.  plot_feature_matrix(featMat,    is_normalised = FALSE,    id_var = \"id\",    method = \"RobustSigmoid\",   clust_method = \"average\",   interactive = FALSE) #> plot_feature_matrix is deprecated as of v0.3.6. Please use 'plot_al_features' instead."},{"path":"https://hendersontrent.github.io/theft/reference/plot_low_dimension.html","id":null,"dir":"Reference","previous_headings":"","what":"Produce a principal components analysis (PCA) on normalised feature values and render a bivariate plot to visualise it — plot_low_dimension","title":"Produce a principal components analysis (PCA) on normalised feature values and render a bivariate plot to visualise it — plot_low_dimension","text":"Produce principal components analysis (PCA) normalised feature values render bivariate plot visualise ","code":""},{"path":"https://hendersontrent.github.io/theft/reference/plot_low_dimension.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Produce a principal components analysis (PCA) on normalised feature values and render a bivariate plot to visualise it — plot_low_dimension","text":"","code":"plot_low_dimension(   data,   is_normalised = FALSE,   id_var = \"id\",   group_var = NULL,   method = c(\"z-score\", \"Sigmoid\", \"RobustSigmoid\", \"MinMax\"),   low_dim_method = c(\"PCA\", \"t-SNE\"),   perplexity = 30,   plot = TRUE,   show_covariance = FALSE,   seed = 123 )"},{"path":"https://hendersontrent.github.io/theft/reference/plot_low_dimension.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Produce a principal components analysis (PCA) on normalised feature values and render a bivariate plot to visualise it — plot_low_dimension","text":"data dataframe least 2 columns called \"names\" \"values\" is_normalised Boolean whether input feature values already scaled. Defaults FALSE id_var string specifying ID variable uniquely identify time series. Defaults \"id\" group_var string specifying grouping variable data aggregates (one exists). Defaults NULL method rescaling/normalising method apply. Defaults \"z-score\" low_dim_method low dimensional embedding method use. Defaults \"PCA\" perplexity perplexity hyperparameter use t-SNE algorithm selected. Defaults 30 plot Boolean whether plot model fit information returned. Defaults TRUE show_covariance Boolean whether covariance ellipses shown plot. Defaults FALSE seed fixed number R's random number generator ensure reproducibility","code":""},{"path":"https://hendersontrent.github.io/theft/reference/plot_low_dimension.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Produce a principal components analysis (PCA) on normalised feature values and render a bivariate plot to visualise it — plot_low_dimension","text":"plot = TRUE, returns object class ggplot, plot = FALSE returns object class dataframe PCA results","code":""},{"path":"https://hendersontrent.github.io/theft/reference/plot_low_dimension.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Produce a principal components analysis (PCA) on normalised feature values and render a bivariate plot to visualise it — plot_low_dimension","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theft/reference/plot_low_dimension.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Produce a principal components analysis (PCA) on normalised feature values and render a bivariate plot to visualise it — plot_low_dimension","text":"","code":"# \\donttest{ featMat <- calculate_features(data = simData,    id_var = \"id\",    time_var = \"timepoint\",    values_var = \"values\",    group_var = \"process\",    feature_set = \"catch22\",   seed = 123) #> No IDs removed. All value vectors good for feature extraction. #> Running computations for catch22... #>  #> Calculations completed for catch22.  plot_low_dimension(featMat,    is_normalised = FALSE,    id_var = \"id\",    group_var = \"group\",    method = \"RobustSigmoid\",    low_dim_method = \"PCA\",    plot = TRUE,   show_covariance = TRUE,   seed = 123)  # }"},{"path":"https://hendersontrent.github.io/theft/reference/plot_quality_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Produce a matrix visualisation of data types computed by feature calculation function. — plot_quality_matrix","title":"Produce a matrix visualisation of data types computed by feature calculation function. — plot_quality_matrix","text":"Produce matrix visualisation data types computed feature calculation function.","code":""},{"path":"https://hendersontrent.github.io/theft/reference/plot_quality_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Produce a matrix visualisation of data types computed by feature calculation function. — plot_quality_matrix","text":"","code":"plot_quality_matrix(data)"},{"path":"https://hendersontrent.github.io/theft/reference/plot_quality_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Produce a matrix visualisation of data types computed by feature calculation function. — plot_quality_matrix","text":"data dataframe least 2 columns called \"names\" \"values\"","code":""},{"path":"https://hendersontrent.github.io/theft/reference/plot_quality_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Produce a matrix visualisation of data types computed by feature calculation function. — plot_quality_matrix","text":"object class ggplot","code":""},{"path":"https://hendersontrent.github.io/theft/reference/plot_quality_matrix.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Produce a matrix visualisation of data types computed by feature calculation function. — plot_quality_matrix","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theft/reference/plot_quality_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Produce a matrix visualisation of data types computed by feature calculation function. — plot_quality_matrix","text":"","code":"featMat <- calculate_features(data = simData,    id_var = \"id\",    time_var = \"timepoint\",    values_var = \"values\",    group_var = \"process\",    feature_set = \"catch22\",   seed = 123) #> No IDs removed. All value vectors good for feature extraction. #> Running computations for catch22... #>  #> Calculations completed for catch22.  plot_quality_matrix(data = featMat)"},{"path":"https://hendersontrent.github.io/theft/reference/plot_ts_correlations.html","id":null,"dir":"Reference","previous_headings":"","what":"Produce a correlation matrix plot showing pairwise correlations of time series with automatic hierarchical clustering — plot_ts_correlations","title":"Produce a correlation matrix plot showing pairwise correlations of time series with automatic hierarchical clustering — plot_ts_correlations","text":"Produce correlation matrix plot showing pairwise correlations time series automatic hierarchical clustering","code":""},{"path":"https://hendersontrent.github.io/theft/reference/plot_ts_correlations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Produce a correlation matrix plot showing pairwise correlations of time series with automatic hierarchical clustering — plot_ts_correlations","text":"","code":"plot_ts_correlations(   data,   is_normalised = FALSE,   id_var = \"id\",   time_var = \"timepoint\",   values_var = \"values\",   method = c(\"z-score\", \"Sigmoid\", \"RobustSigmoid\", \"MinMax\"),   clust_method = c(\"average\", \"ward.D\", \"ward.D2\", \"single\", \"complete\", \"mcquitty\",     \"median\", \"centroid\"),   cor_method = c(\"pearson\", \"spearman\"),   interactive = FALSE )"},{"path":"https://hendersontrent.github.io/theft/reference/plot_ts_correlations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Produce a correlation matrix plot showing pairwise correlations of time series with automatic hierarchical clustering — plot_ts_correlations","text":"data dataframewith least 2 columns \"id\" \"values\" variables is_normalised Boolean whether input feature values already scaled. Defaults FALSE id_var string specifying ID variable compute pairwise correlations . Defaults \"id\" time_var string specifying time index variable. Defaults NULL values_var string denoting name variable/column holds numerical feature values. Defaults \"values\" method rescaling/normalising method apply. Defaults \"RobustSigmoid\" clust_method hierarchical clustering method use pairwise correlation plot. Defaults \"average\" cor_method correlation method use. Defaults \"pearson\" interactive Boolean whether plot interactive plotly graphic. Defaults FALSE","code":""},{"path":"https://hendersontrent.github.io/theft/reference/plot_ts_correlations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Produce a correlation matrix plot showing pairwise correlations of time series with automatic hierarchical clustering — plot_ts_correlations","text":"object class ggplot","code":""},{"path":"https://hendersontrent.github.io/theft/reference/plot_ts_correlations.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Produce a correlation matrix plot showing pairwise correlations of time series with automatic hierarchical clustering — plot_ts_correlations","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theft/reference/plot_ts_correlations.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Produce a correlation matrix plot showing pairwise correlations of time series with automatic hierarchical clustering — plot_ts_correlations","text":"","code":"plot_ts_correlations(data = simData,    is_normalised = FALSE,    id_var = \"id\",    time_var = \"timepoint\",   values_var = \"values\",   method = \"RobustSigmoid\",   cor_method = \"pearson\",   clust_method = \"average\",   interactive = FALSE)"},{"path":"https://hendersontrent.github.io/theft/reference/process_hctsa_file.html","id":null,"dir":"Reference","previous_headings":"","what":"Load in hctsa formatted MATLAB files of time series data into a tidy format ready for feature extraction — process_hctsa_file","title":"Load in hctsa formatted MATLAB files of time series data into a tidy format ready for feature extraction — process_hctsa_file","text":"Load hctsa formatted MATLAB files time series data tidy format ready feature extraction","code":""},{"path":"https://hendersontrent.github.io/theft/reference/process_hctsa_file.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load in hctsa formatted MATLAB files of time series data into a tidy format ready for feature extraction — process_hctsa_file","text":"","code":"process_hctsa_file(data)"},{"path":"https://hendersontrent.github.io/theft/reference/process_hctsa_file.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load in hctsa formatted MATLAB files of time series data into a tidy format ready for feature extraction — process_hctsa_file","text":"data string specifying filepath MATLAB file parse","code":""},{"path":"https://hendersontrent.github.io/theft/reference/process_hctsa_file.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load in hctsa formatted MATLAB files of time series data into a tidy format ready for feature extraction — process_hctsa_file","text":"object class dataframe tidy format","code":""},{"path":"https://hendersontrent.github.io/theft/reference/process_hctsa_file.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Load in hctsa formatted MATLAB files of time series data into a tidy format ready for feature extraction — process_hctsa_file","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theft/reference/process_hctsa_file.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load in hctsa formatted MATLAB files of time series data into a tidy format ready for feature extraction — process_hctsa_file","text":"","code":"# \\donttest{ myfile <- process_hctsa_file(   \"https://cloudstor.aarnet.edu.au/plus/s/6sRD6IPMJyZLNlN/download\"   ) # }"},{"path":"https://hendersontrent.github.io/theft/reference/robustsigmoid_scaler.html","id":null,"dir":"Reference","previous_headings":"","what":"This function rescales a vector of numerical values with an outlier-robust Sigmoidal transformation — robustsigmoid_scaler","title":"This function rescales a vector of numerical values with an outlier-robust Sigmoidal transformation — robustsigmoid_scaler","text":"function rescales vector numerical values outlier-robust Sigmoidal transformation","code":""},{"path":"https://hendersontrent.github.io/theft/reference/robustsigmoid_scaler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"This function rescales a vector of numerical values with an outlier-robust Sigmoidal transformation — robustsigmoid_scaler","text":"","code":"robustsigmoid_scaler(x, unitInt = TRUE)"},{"path":"https://hendersontrent.github.io/theft/reference/robustsigmoid_scaler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"This function rescales a vector of numerical values with an outlier-robust Sigmoidal transformation — robustsigmoid_scaler","text":"x numeric vector, preferably feature values computed theft package functions unitInt Booelan whether rescale Sigmoidal outputs unit interval [0,1]. Defaults TRUE","code":""},{"path":"https://hendersontrent.github.io/theft/reference/robustsigmoid_scaler.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"This function rescales a vector of numerical values with an outlier-robust Sigmoidal transformation — robustsigmoid_scaler","text":"x numeric rescaled vector","code":""},{"path":"https://hendersontrent.github.io/theft/reference/robustsigmoid_scaler.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"This function rescales a vector of numerical values with an outlier-robust Sigmoidal transformation — robustsigmoid_scaler","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theft/reference/robustsigmoid_scaler.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"This function rescales a vector of numerical values with an outlier-robust Sigmoidal transformation — robustsigmoid_scaler","text":"","code":"robustsigmoid_scaler(stats::rnorm(10)) #>  [1] 0.2309227 0.3776043 0.9801462 0.5185956 0.5457810 1.0000000 0.6898731 #>  [8] 0.0000000 0.1801651 0.2799617"},{"path":"https://hendersontrent.github.io/theft/reference/sigmoid_scaler.html","id":null,"dir":"Reference","previous_headings":"","what":"This function rescales a vector of numerical values with a Sigmoidal transformation — sigmoid_scaler","title":"This function rescales a vector of numerical values with a Sigmoidal transformation — sigmoid_scaler","text":"function rescales vector numerical values Sigmoidal transformation","code":""},{"path":"https://hendersontrent.github.io/theft/reference/sigmoid_scaler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"This function rescales a vector of numerical values with a Sigmoidal transformation — sigmoid_scaler","text":"","code":"sigmoid_scaler(x, unitInt = TRUE)"},{"path":"https://hendersontrent.github.io/theft/reference/sigmoid_scaler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"This function rescales a vector of numerical values with a Sigmoidal transformation — sigmoid_scaler","text":"x numeric vector, preferably feature values computed theft package functions unitInt Booelan whether rescale Sigmoidal outputs unit interval [0,1]. Defaults TRUE","code":""},{"path":"https://hendersontrent.github.io/theft/reference/sigmoid_scaler.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"This function rescales a vector of numerical values with a Sigmoidal transformation — sigmoid_scaler","text":"x numeric rescaled vector","code":""},{"path":"https://hendersontrent.github.io/theft/reference/sigmoid_scaler.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"This function rescales a vector of numerical values with a Sigmoidal transformation — sigmoid_scaler","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theft/reference/sigmoid_scaler.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"This function rescales a vector of numerical values with a Sigmoidal transformation — sigmoid_scaler","text":"","code":"sigmoid_scaler(stats::rnorm(10)) #>  [1] 0.8680223 0.6002433 0.6140205 0.5159792 0.3013074 1.0000000 0.6464569 #>  [8] 0.0000000 0.7129473 0.3262809"},{"path":"https://hendersontrent.github.io/theft/reference/simData.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample of randomly-generated time series to produce function tests and vignettes — simData","title":"Sample of randomly-generated time series to produce function tests and vignettes — simData","text":"variables include:","code":""},{"path":"https://hendersontrent.github.io/theft/reference/simData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample of randomly-generated time series to produce function tests and vignettes — simData","text":"","code":"simData"},{"path":"https://hendersontrent.github.io/theft/reference/simData.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Sample of randomly-generated time series to produce function tests and vignettes — simData","text":"tidy dataframe 4 variables: id Unique identifier time series timepoint Time index values Value process Group label type time series","code":""},{"path":"https://hendersontrent.github.io/theft/reference/theft.html","id":null,"dir":"Reference","previous_headings":"","what":"Tools for Handling Extraction of Features from Time-series — theft","title":"Tools for Handling Extraction of Features from Time-series — theft","text":"Tools Handling Extraction Features Time-series","code":""},{"path":"https://hendersontrent.github.io/theft/reference/zscore_scaler.html","id":null,"dir":"Reference","previous_headings":"","what":"This function rescales a vector of numerical values into z-scores — zscore_scaler","title":"This function rescales a vector of numerical values into z-scores — zscore_scaler","text":"function rescales vector numerical values z-scores","code":""},{"path":"https://hendersontrent.github.io/theft/reference/zscore_scaler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"This function rescales a vector of numerical values into z-scores — zscore_scaler","text":"","code":"zscore_scaler(x, unitInt = TRUE)"},{"path":"https://hendersontrent.github.io/theft/reference/zscore_scaler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"This function rescales a vector of numerical values into z-scores — zscore_scaler","text":"x numeric vector, preferably feature values computed theft package functions unitInt Booelan whether rescale outputs unit interval [0,1]. Defaults TRUE","code":""},{"path":"https://hendersontrent.github.io/theft/reference/zscore_scaler.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"This function rescales a vector of numerical values into z-scores — zscore_scaler","text":"x numeric vector, rescaled z-scores","code":""},{"path":"https://hendersontrent.github.io/theft/reference/zscore_scaler.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"This function rescales a vector of numerical values into z-scores — zscore_scaler","text":"Trent Henderson","code":""},{"path":"https://hendersontrent.github.io/theft/reference/zscore_scaler.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"This function rescales a vector of numerical values into z-scores — zscore_scaler","text":"","code":"zscore_scaler(stats::rnorm(10)) #>  [1] 0.2104635 0.4994777 0.2246853 0.3257267 0.3610444 0.0000000 0.8585184 #>  [8] 0.6257648 0.1865516 1.0000000"}]
